<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Tracking Semantic Changes in Medical Information | Social &amp; Computational Intelligence Research </title> <meta name="author" content="Ritwik Banerjee"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link href="https://fonts.googleapis.com/css2?family=Nunito:wght@200;400;600;700&amp;display=swap" rel="stylesheet"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/scire-logo.png?bf02603fb8aaabc10642c7e0cff8af7a"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sciresearch.github.io/projects/nsf-eager-tracking-2018/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Mission </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Tracking Semantic Changes in Medical Information </h1> <p class="post-description"> </p> </header> <article> <hr> <h6 class="project-sponsor">This research is funded by the <strong>Secure &amp; Trustworthy Cyberspace (SaTC)</strong> program of the <strong>U.S. National Science Foundation (NSF)</strong> </h6> <h6 class="project-sponsor"> <span style="font-weight: 400; font-size: 0.8rem;"> <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1834597" rel="external nofollow noopener" target="_blank">SES-1834597</a> </span> <span style="font-weight: 800;"> | </span> <span style="font-weight: 400; font-size: 0.8rem;"> 05.2018 - 03.2022 </span> </h6> <blockquote class="block-tip"> <p><a href="https://www.ritwikbanerjee.com" rel="external nofollow noopener" target="_blank"><strong>Ritwik Banerjee</strong></a> | Principal Investigator <br> Chaoyuan Zuo, Ph.D.  ⇒  Faculty @ School of Journalism &amp; Communication, Nankai University (China) <br> Noushin Salek Faramarzi, Ph.D.  ⇒  Natural Language Understanding @ Boeing <br> Kritik Mathur, M.S.  ⇒  Software Engineer @ Amazon <br> Dhruv Kela, M.S.  ⇒  Software Engineer @ DigitalOcean <br> Narayan Acharya, M.S.  ⇒  Research Engineer @ dmetrics, Inc. <br> Ayla Karakas, B.S. (Linguistics) Ph.D.,  ⇒  Computational Linguistics @ Yale <br> Qi Zhang, B.S.  ⇒  MS, University of California San Diego</p> </blockquote> <blockquote class="block-warning"> <h5 id="collaborators">Collaborators</h5> <p><a href="https://www.cs.colostate.edu/~iray" rel="external nofollow noopener" target="_blank"><strong>Indrakshi Ray</strong></a>, Colorado State University <br> <a href="https://www.hosseinshirazi.info/" rel="external nofollow noopener" target="_blank"><strong>Hossein Shirazi</strong></a>, San Diego State University <br> Fateme Hashemi Chaleshtori, M.S., Colorado State University <br> Sina Mahdipour Saravani, M.S., Colorado State University</p> </blockquote> <hr> <h4 id="overview">Overview</h4> <p>In this groundbreaking research, our team tackled a major issue plaguing today’s digital world: <strong>how medical information can change as it moves from research papers to news articles and social media posts</strong>. Changes in the meaning of information as it passes through cyberspace can mislead those who access the information, making it crucial to understand these transformations.</p> <p>By focusing on subtle shifts in meaning – like oversimplification or selective reporting – the project reveals how even well-cited and reputable medical news can mislead readers. Instead of imposing an external <code class="language-plaintext highlighter-rouge">true/false</code> label on information, this research looks into a series of changes within the news coverage itself that gradually lead to a deviation from the original claims. Our team explored information change in narratives, including semantic changes and nuances, or selective emphasis of related information.</p> <p>Using advanced information retrieval (IR) and deep neural network models, we studied these shifts <em>without relying on human judgment</em>, marking the first-ever AI-driven cross-genre analysis of health misinformation. This approach went beyond contemporary methods limited to binary labels and avoided the potential biases imposed by external fact-checkers. One major finding showed that <strong>at least 1% of social media posts citing reputable news sources used those citations deceptively, creating false trust</strong>.</p> <p>Our research developed new datasets and algorithms to identify and categorize medical information that remains true to the original meaning or undergoes distortion. Identifying important differences between original articles and news stories is a challenging venture with a significant risk-reward tradeoff, but the research produced valuable tools for verifying health-related claims across genres and trained the next generation of researchers.</p> <p><strong>Broader impacts:</strong> This research offers benefits to the research community by making novel contributions to understanding temporal changes in natural language information, as well as social benefits in the form of improved informational tools. For the medical domain in particular, understanding temporal distortions and deviations from actual medical findings can reduce occurrences of harmful health choices, for instance, by embedding the research outcomes in news, social media, or search engines. Through this project, we highlight how AI can help protect us from misleading information in health-related news and social media <em>without reliance on external sources of expertise for their opinions</em>.</p> <hr> <p>As a first step in this direction, we focused on identifying what information is worth verifying, and developed a hybrid method comprising heuristics and supervised learning to identify “check-worthy” information <a class="citation" href="#zuo2018hybrid">(Zuo et al.; , 2018)</a>. Our approach achieved the best state-of-the-art detection, as measured by several metrics. An expansion on this work was invited to the CLEF 2019 conference <a class="citation" href="#zuo2019tocheck">(Zuo et al.; , 2019)</a>.</p> <p>Next, we looked into how healthcare information is first presented in research literature, and then in newswires for general readership. We developed a novel dataset of 5,034 news articles paired with the research abstracts of the work being mentioned, and explored how to identify identical or near-identical content expressed in vastly different syntax and vocabulary. For this, we took a two-step approach: (1) select the most relevant candidates from a collection of 222,000 research abstracts, and (2) re-rank this list of most relevant candidates. We compared the classical approach of information retrieval (IR) using BM25 with more recent transformer-based models, and find that cross-genre medical IR is a viable task, but incorporating domain-specific knowledge is crucial for its success <a class="citation" href="#zuo2020querying">(Zuo et al.; , 2020)</a>.</p> <p>Through the course of this project, we observed that the complex nature of medical misinformation can be attributed largely to two phenomena. First, (mis)information propagates across multiple distinct genres — from research literature to newswires to social media, where each genre has its own linguistic properties and pragmatic hurdles to overcome. Second, a large amount of information amounts to paltering, or what is often called “less than lying”. We have pursued scientific investigations in both directions.</p> <h5 id="misinformation-propagation-across-genres">(Mis)information propagation across genres</h5> <p>In the former, we looked into the phenomenon of linguistic transformations that happen when medical information transitions from specialized research literature into news intended for wider readership. This transition makes the information vulnerable to misinterpretation, misrepresentation, and incorrect attribution, all of which may be difficult to identify without adequate domain knowledge and may exist even in the presence of explicit citations. Moreover, news articles seldom provide a precise correspondence between a specific claim and its origin, making it harder to identify which claims, if any, reflect the original findings. For instance, an article stating “Flagellin shows therapeutic potential with H3N2, known as Aussie Flu.” contains two claims (“Flagellin … H3N2,” and “H3N2, known as Aussie Flu”) that may be true or false independent of each other, and it is prima facie unclear which claims, if any, are supported by the cited research. We developed a corpus of sentences from medical news along with the sources from peer-reviewed medical research journals these news articles cite. Then, we used this corpus to study what a general reader perceives to be true, and how to verify the scientific source of claims. Unlike existing corpora, this captures the metamorphosis of information across two genres with disparate readership and vastly different vocabularies and presents the first empirical study of health-related fact-checking across them <a class="citation" href="#zuo2022beyond">(Zuo et al.; , 2022)</a>.</p> <p>We ventured further into the cross-genre propagation of misinformation and the perception of truth. For this part of our research, we collaborated with a team led by Dr. Indrakshi Ray at Colorado State University, Fort Collins. As prior research has often demonstrated, social media posts often leverage the trust readers have in prestigious news agencies and cite news articles as a way of gaining credibility. It is not, however, always the case that the cited article supports the claim being upheld in the social media post. In other words, the post makes it “look” like the claim originates from a credible source, but it really does not! We develop a cross-genre ad hoc information retrieval model to identify whether the information in a Twitter post is, indeed, supported by the news article it cites. This leg of our work rests on a large corpus of 46.86 million Twitter posts about COVID-19, and is divided into two tasks: (i) development of models to detect Tweets containing claim and worth to be fact-checked and (ii) verifying whether the claims made in a Tweet are supported by the newswire article it cites. Unlike previous studies that detect unsubstantiated information by post hoc analysis of the patterns of propagation, our approach is capable of identifying deceptive support before the misinformation begins to spread. Among our chief findings is the observation that among the posts that contain a seemingly factual claim while citing a news article as supporting evidence, at least 1% include a citation intended to deceive the reader <a class="citation" href="#zuo2022seeing">(Zuo et al.; , 2022)</a>.</p> <h5 id="less-than-lying">Less than lying</h5> <p>The latter consists of selective reporting, non-disclosure of conflicts of interests, disease-mongering, etc. These manifold attributes make the automatic detection of medical misinformation a daunting challenge, and has so far only been explored by journalists and healthcare professionals in purely qualitative studies. We delved into a significantly more complex multi-class classification task to test whether medical news articles (most of which are not considered “fake” by any existing fact-checking system) actually satisfy criteria deemed important by medical experts and healthcare journalists (as far as misinformation is concerned). We collected a corpus of 1,119 health news paired with systematic reviews, where each review has six criteria essential to the accuracy of medical news. Our experiments compared classical token-based approaches with the more recent transformer-based models, and found that detecting qualitative lapses is an extremely challenging task with direct ramifications in misinformation. Moreover, it is an important direction to pursue beyond assigning True or False labels to short claims <a class="citation" href="#zuo2021empirical">(Zuo et al.; , 2021)</a>.</p> <p><a class="citation" href="#saravani2021investigation">(Saravani et al.; , 2021)</a></p> <p><a class="citation" href="#banerjee2021diagnosis">(Banerjee and Ray; , 2021)</a></p> <hr> <h4 id="publications">Publications</h4> <blockquote class="block-references"> <p><span id="zuo2018hybrid">Chaoyuan Zuo, Ayla Karakas, and Ritwik Banerjee. 2018. A Hybrid Recognition System for Check-worthy Claims Using Heuristics and Supervised Learning. In Linda Cappellato, Nicola Ferro, Jian-Yun Nie, and Laure Soulier, editors, <i>CLEF 2018 Working Notes. Working Notes of CLEF 2018 - Conference and Labs of the Evaluation Forum</i>, Avignon, France, . CEUR-WS.org.</span>      <a href="/assets/pdf/zuo2018hybrid-clef.pdf"><i class="fas fa-file-pdf"></i></a> <br><br> <span id="zuo2019tocheck">Chaoyuan Zuo, Ayla Ida Karakas, and Ritwik Banerjee. 2019. To Check or Not to Check: Syntax, Semantics, and Context in the Language of Check-Worthy Claims. In F. Crestani, M. Braschler, J. Savoy, A. Rauber, H. Müller, D. E. Losada, G. Heinatz Bürki, L. Cappellato, and N. Ferro, editors, <i>Experimental IR Meets Multilinguality, Multimodality, and Interaction</i>, pages 271–283, Cham, . Springer. Invited Paper.</span>      <a href="/assets/pdf/zuo2018tocheck-clef.pdf"><i class="fas fa-file-pdf"></i></a> <br><br> <span id="zuo2020querying">Chaoyuan Zuo, Narayan Acharya, and Ritwik Banerjee. 2020. Querying Across Genres for Medical Claims in News. In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu, editors, <i>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>, pages 1783–1789, Online, November. Association for Computational Linguistics.</span>      <a href="/assets/pdf/zuo2020querying.pdf"><i class="fas fa-file-pdf"></i></a> <br><br> <span id="zuo2022beyond">Chaoyuan Zuo, Kritik Mathur, Dhruv Kela, Noushin Salek Faramarzi, and Ritwik Banerjee. 2022. Beyond belief: a cross-genre study on perception and validation of health information online. <i>International Journal of Data Science and Analytics</i>, 13(4):299–314, February.</span>      <a href="/assets/pdf/zuo2022beyond-journal.pdf"><i class="fas fa-file-pdf"></i></a> <br><br> <span id="zuo2022seeing">Chaoyuan Zuo, Ritwik Banerjee, Fateme Hashemi Chaleshtori, Hossein Shirazi, and Indrakshi Ray. 2022. Seeing Should Probably Not Be Believing: The Role of Deceptive Support in COVID-19 Misinformation on Twitter. <i>Journal of Data and Information Quality</i>, 15(1), December.</span>      <a href="/assets/pdf/zuo2022seeing-journal.pdf"><i class="fas fa-file-pdf"></i></a> <br><br> <span id="zuo2021empirical">Chaoyuan Zuo, Qi Zhang, and Ritwik Banerjee. 2021. An Empirical Assessment of the Qualitative Aspects of Misinformation in Health News. In Anna Feldman, Giovanni Da San Martino, Chris Leberknight, and Preslav Nakov, editors, <i>Proceedings of the Fourth Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda</i>, pages 76–81, Online, June. Association for Computational Linguistics.</span>      <a href="/assets/pdf/zuo2021empirical.pdf"><i class="fas fa-file-pdf"></i></a> <br><br> <span id="saravani2021investigation">Sina Mahdipour Saravani, Ritwik Banerjee, and Indrakshi Ray. 2021. An Investigation into the Contribution of Locally Aggregated Descriptors to Figurative Language Identification. In João Sedoc, Anna Rogers, Anna Rumshisky, and Shabnam Tafreshi, editors, <i>Proceedings of the Second Workshop on Insights from Negative Results in NLP</i>, pages 103–109, Online and Punta Cana, Dominican Republic, November. Association for Computational Linguistics.</span>      <a href="/assets/pdf/saravani2021investigation.pdf"><i class="fas fa-file-pdf"></i></a> <br><br> <span id="banerjee2021diagnosis">Ritwik Banerjee and Indrakshi Ray. 2021. Diagnosis, Prevention, and Cure for Misinformation *. In <i>2021 IEEE Third International Conference on Cognitive Machine Intelligence (CogMI)</i>, pages 156–162, Atlanta, GA, USA, . IEEE.</span>      <a href="https://par.nsf.gov/servlets/purl/10341221" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-pdf"></i></a></p> </blockquote> <p><br> <br> <span style="float: right; font-weight: 200; font-size: 0.75rem;"><i>This project page is hosted and maintained by the principal investigator, <a href="https://www.ritwikbanerjee.com" rel="external nofollow noopener" target="_blank">Dr. Ritwik Banerjee</a>.</i></span></p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ritwik Banerjee. Social &amp; Computational Intelligence Research Department of Computer Science, Stony Brook University </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>